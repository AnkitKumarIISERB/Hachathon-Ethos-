{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1bcFPOZk-bzLgMCLnnkVWGucNCJCQ7F3C",
      "authorship_tag": "ABX9TyPKRlD1p/W835C1MjtL0SKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkitKumarIISERB/Hachathon-Ethos-/blob/main/production.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isAzmHmIGOKl",
        "outputId": "5ab832b5-8aee-4066-cbff-8451e633fa75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting markovify\n",
            "  Downloading markovify-0.9.4-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting unidecode (from markovify)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markovify-0.9.4-py3-none-any.whl (19 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, unidecode, rapidfuzz, markovify, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 fuzzywuzzy-0.18.0 markovify-0.9.4 python-Levenshtein-0.27.1 rapidfuzz-3.14.1 unidecode-1.4.0\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# CAMPUS ENTITY RESOLUTION & SECURITY SYSTEM\n",
        "# Google Colab End-to-End Notebook\n",
        "# ===========================================\n",
        "\n",
        "# 1️⃣ SETUP & IMPORTS\n",
        "# -------------------\n",
        "!pip install fuzzywuzzy python-Levenshtein markovify scikit-learn networkx tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import networkx as nx\n",
        "from fuzzywuzzy import fuzz, process\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "import markovify\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ MOUNT DRIVE (IF USING DRIVE)\n",
        "# --------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/campus_data\"   # <-- place your 8 CSVs here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOI_UPtFJbEr",
        "outputId": "eb9ee332-f5d0-4fea-bb1b-12ea7e0f7e24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3️⃣ COLUMN MAPPING (handles inconsistent naming)\n",
        "# ------------------------------------------------\n",
        "COLUMN_MAPPING = {\n",
        "    'student_id': 'entity_id',\n",
        "    'user_id': 'entity_id',\n",
        "    'person_id': 'entity_id',\n",
        "    'card_id': 'card_id',\n",
        "    'face_id': 'face_id',\n",
        "    'device_hash': 'device_id',\n",
        "    'location_id': 'location_id',\n",
        "    'loc_id': 'location_id',\n",
        "    'timestamp': 'timestamp',\n",
        "    'time': 'timestamp',\n",
        "    'datetime': 'timestamp',\n",
        "    'email_id': 'email',\n",
        "    'mail': 'email',\n",
        "    'full_name': 'name',\n",
        "    'user_name': 'name'\n",
        "}\n",
        "\n",
        "def normalize_columns(df):\n",
        "    df = df.rename(columns={c: COLUMN_MAPPING.get(c.lower(), c.lower()) for c in df.columns})\n",
        "    if 'timestamp' in df.columns:\n",
        "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "    return df"
      ],
      "metadata": {
        "id": "iPkloCH0Jx7K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4️⃣ LOAD ALL CSVs\n",
        "# -----------------\n",
        "def load_csv(name):\n",
        "    path = os.path.join(DATA_DIR, name)\n",
        "    df = pd.read_csv(path)\n",
        "    df = normalize_columns(df)\n",
        "    df['source'] = name\n",
        "    return df\n",
        "\n",
        "files = [\n",
        "    \"card_swipes.csv\",\n",
        "    \"cctv_frames.csv\",\n",
        "    \"face_embeddings.csv\",\n",
        "    \"free_text_notes.csv\",\n",
        "    \"lab_bookings.csv\",\n",
        "    \"library_checkouts.csv\",\n",
        "    \"profiles.csv\",\n",
        "    \"wifi_associations_logs.csv\"\n",
        "]\n",
        "\n",
        "dataframes = {f: load_csv(f) for f in files}"
      ],
      "metadata": {
        "id": "jBYPyF0-J_cK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5️⃣ BASIC CLEANING\n",
        "# ------------------\n",
        "for name, df in dataframes.items():\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    if 'timestamp' in df.columns:\n",
        "        df = df.sort_values('timestamp')\n",
        "    dataframes[name] = df"
      ],
      "metadata": {
        "id": "X9pNB1HxKDfq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building entity graph for resolution...\")\n",
        "\n",
        "G = nx.Graph()\n",
        "\n",
        "for name, df in tqdm(dataframes.items()):\n",
        "    # Ensure no duplicate column names\n",
        "    df.columns = df.columns.map(str)\n",
        "    df = df.loc[:, ~df.columns.duplicated()]\n",
        "\n",
        "    id_cols = ['entity_id', 'card_id', 'face_id', 'device_id', 'email']\n",
        "    id_cols = [c for c in id_cols if c in df.columns]\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        identifiers = []\n",
        "        for col in id_cols:\n",
        "            try:\n",
        "                # Safely extract scalar value\n",
        "                val = row[col]\n",
        "                if isinstance(val, (list, dict, pd.Series)):\n",
        "                    continue\n",
        "                if pd.notna(val) and str(val).strip():\n",
        "                    identifiers.append(str(val).strip())\n",
        "            except Exception:\n",
        "                continue  # skip invalid entries gracefully\n",
        "\n",
        "        # Connect all IDs found in this record\n",
        "        if len(identifiers) > 1:\n",
        "            for i in range(len(identifiers)):\n",
        "                for j in range(i + 1, len(identifiers)):\n",
        "                    G.add_edge(identifiers[i], identifiers[j], source=name)\n",
        "\n",
        "print(f\"✅ Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3dPY3OVKrOp",
        "outputId": "b8acd6f1-e11f-4906-db29-6348929e1885"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building entity graph for resolution...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:04<00:00,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Graph built with 30860 nodes and 62000 edges\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7️⃣ CREATE ENTITY GROUPS\n",
        "# ===========================================\n",
        "\n",
        "entity_groups = list(nx.connected_components(G))\n",
        "print(f\"Total connected components (entities): {len(entity_groups)}\")\n",
        "\n",
        "entity_map = {}\n",
        "for i, group in enumerate(entity_groups):\n",
        "    for node in group:\n",
        "        entity_map[node] = f\"E{i+1}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnm2DgYKt9J",
        "outputId": "9e823d84-4a12-4d61-a312-15f2b71bd58d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total connected components (entities): 4860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8️⃣ APPLY ENTITY MAPPING TO ALL DATAFRAMES\n",
        "# ===========================================\n",
        "import numpy as np\n",
        "\n",
        "for name, df in dataframes.items():\n",
        "    if 'resolved_entity' not in df.columns:\n",
        "        df['resolved_entity'] = np.nan\n",
        "\n",
        "    for key in ['entity_id', 'card_id', 'face_id', 'device_id', 'email']:\n",
        "        if key in df.columns:\n",
        "            # force Series (handle duplicate columns or bad read)\n",
        "            col_data = df[key]\n",
        "            if isinstance(col_data, pd.DataFrame):\n",
        "                # if there are duplicate columns, take the first one\n",
        "                col_data = col_data.iloc[:, 0]\n",
        "\n",
        "            # ensure type conversion\n",
        "            mapped_vals = col_data.astype(str).map(entity_map)\n",
        "\n",
        "            # update resolved_entity only where it’s still NaN\n",
        "            df.loc[df['resolved_entity'].isna(), 'resolved_entity'] = mapped_vals\n",
        "\n",
        "    dataframes[name] = df\n",
        "\n",
        "print(\"✅ Successfully mapped resolved_entity for all datasets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIkqBe2tLrkp",
        "outputId": "cb1a5d98-f2fd-4296-bcaa-8828267f3a40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully mapped resolved_entity for all datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9️⃣ MERGE ALL SOURCES INTO A MASTER DATAFRAME\n",
        "# ===========================================\n",
        "\n",
        "# ===========================================\n",
        "# 🧩 Step: Clean column names and reset indexes before merging\n",
        "# ===========================================\n",
        "cleaned_dfs = []\n",
        "for name, df in dataframes.items():\n",
        "    # 1️⃣ Reset index to avoid duplicate index labels\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # 2️⃣ Remove duplicate column names (keep first)\n",
        "    df = df.loc[:, ~df.columns.duplicated()].copy()\n",
        "\n",
        "    # 3️⃣ Add source column to track origin\n",
        "    df[\"source\"] = name\n",
        "\n",
        "    # 4️⃣ Standardize timestamp column if missing\n",
        "    if \"timestamp\" not in df.columns:\n",
        "        for alt in [\"time\", \"date_time\", \"datetime\"]:\n",
        "            if alt in df.columns:\n",
        "                df.rename(columns={alt: \"timestamp\"}, inplace=True)\n",
        "                break\n",
        "\n",
        "    cleaned_dfs.append(df)\n",
        "\n",
        "# ===========================================\n",
        "# 🧩 Step: Merge all cleaned DataFrames safely\n",
        "# ===========================================\n",
        "merged_df = pd.concat(cleaned_dfs, ignore_index=True, sort=False)\n",
        "\n",
        "# ===========================================\n",
        "# 🕒 Convert and sort timestamps\n",
        "# ===========================================\n",
        "merged_df[\"timestamp\"] = pd.to_datetime(merged_df[\"timestamp\"], errors=\"coerce\")\n",
        "merged_df = merged_df.sort_values([\"resolved_entity\", \"timestamp\"], ignore_index=True)\n",
        "\n",
        "print(\"✅ All datasets successfully merged into merged_df\")\n",
        "print(f\"Final merged shape: {merged_df.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "merged_df['timestamp'] = pd.to_datetime(merged_df['timestamp'], errors='coerce')\n",
        "merged_df = merged_df.sort_values(['resolved_entity', 'timestamp'])\n",
        "merged_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(f\"✅ Unified dataset shape: {merged_df.shape}\")\n",
        "print(f\"Unique resolved entities: {merged_df['resolved_entity'].nunique()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMeatgxtLvfZ",
        "outputId": "4ee9ca59-0dda-48a4-9c0a-32371d63dc60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All datasets successfully merged into merged_df\n",
            "Final merged shape: (57973, 37)\n",
            "✅ Unified dataset shape: (57973, 37)\n",
            "Unique resolved entities: 4860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔟 FUZZY NAME & EMAIL MATCHING\n",
        "# ===========================================\n",
        "\n",
        "from fuzzywuzzy import process\n",
        "\n",
        "def fuzzy_clean_column(df, column):\n",
        "    \"\"\"Normalize a text column using fuzzy matching for near-duplicates.\"\"\"\n",
        "    if column not in df.columns:\n",
        "        return df\n",
        "    df[column] = df[column].fillna('').astype(str)\n",
        "    unique_vals = [v for v in df[column].unique() if v and len(v) > 2]\n",
        "    canonical = {}\n",
        "    for val in unique_vals:\n",
        "        if val not in canonical:\n",
        "            matches = process.extract(val, unique_vals, limit=3)\n",
        "            for m, score in matches:\n",
        "                if score > 90:\n",
        "                    canonical[m] = val\n",
        "    df[column] = df[column].map(lambda x: canonical.get(x, x))\n",
        "    return df\n",
        "\n",
        "merged_df = fuzzy_clean_column(merged_df, 'name')\n",
        "merged_df = fuzzy_clean_column(merged_df, 'email')\n",
        "\n",
        "print(\"✅ Fuzzy normalization of names/emails completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q5NrTzGMotJ",
        "outputId": "08b778e9-7013-49e8-ecf7-181d79046cb1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fuzzy normalization of names/emails completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11️⃣ TIMELINE GENERATION\n",
        "# ===========================================\n",
        "\n",
        "timeline_df = merged_df.groupby('resolved_entity').apply(\n",
        "    lambda x: x.sort_values('timestamp')[['timestamp', 'location_id', 'source']].to_dict('records')\n",
        ").reset_index().rename(columns={0: 'timeline'})\n",
        "\n",
        "print(f\"✅ Generated timelines for {len(timeline_df)} entities\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vEtz7HnNoyZ",
        "outputId": "5777d7f6-e87c-42ec-b461-9f81e95e7d2a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated timelines for 4860 entities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12️⃣ FEATURE ENGINEERING FOR ML\n",
        "# ===========================================\n",
        "\n",
        "df_ml = merged_df.copy()\n",
        "df_ml = df_ml.dropna(subset=['resolved_entity', 'timestamp'])\n",
        "df_ml['hour'] = df_ml['timestamp'].dt.hour\n",
        "df_ml['dayofweek'] = df_ml['timestamp'].dt.dayofweek\n",
        "df_ml['month'] = df_ml['timestamp'].dt.month\n",
        "df_ml['location_id'] = df_ml['location_id'].astype(str)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_loc = LabelEncoder()\n",
        "df_ml['loc_encoded'] = le_loc.fit_transform(df_ml['location_id'])\n",
        "\n",
        "# Prepare dataset for supervised learning\n",
        "X = df_ml[['hour', 'dayofweek', 'month', 'loc_encoded']]\n",
        "y = df_ml['loc_encoded'].shift(-1).fillna(df_ml['loc_encoded'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"✅ Training / Testing datasets prepared.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYPUvCtdTYVp",
        "outputId": "c81ab9c0-05bc-4a15-82ee-8eaf61be8545"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training / Testing datasets prepared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 13️⃣ RANDOM FOREST MODEL FOR NEXT LOCATION\n",
        "# ===========================================\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=120, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "preds = rf.predict(X_test)\n",
        "print(\"\\n🎯 Random Forest Performance:\\n\")\n",
        "print(classification_report(y_test, preds))\n",
        "\n",
        "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
        "print(\"\\nFeature Importances:\\n\", importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkAvRGS0TkLH",
        "outputId": "0db2acdf-70a0-47fa-a58d-e1ab8e21834d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Random Forest Performance:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00       302\n",
            "         1.0       0.09      0.01      0.02       312\n",
            "         2.0       0.05      0.01      0.01       312\n",
            "         3.0       0.07      0.01      0.01       324\n",
            "         4.0       0.00      0.00      0.00       304\n",
            "         5.0       0.04      0.00      0.01       311\n",
            "         6.0       0.09      0.01      0.01       324\n",
            "         7.0       0.12      0.01      0.02       297\n",
            "         8.0       0.64      0.96      0.77      4357\n",
            "\n",
            "    accuracy                           0.62      6843\n",
            "   macro avg       0.12      0.11      0.09      6843\n",
            "weighted avg       0.43      0.62      0.49      6843\n",
            "\n",
            "\n",
            "Feature Importances:\n",
            " hour           0.492002\n",
            "dayofweek      0.187470\n",
            "month          0.044763\n",
            "loc_encoded    0.275766\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n✅ Building Markov chain transition probabilities...\")\n",
        "\n",
        "# Ensure we have a clean column for locations or states\n",
        "if 'loc_encoded' not in merged_df.columns:\n",
        "    # fallback: use location_encoded or location_id if available\n",
        "    for alt in ['location_encoded', 'location_id', 'location']:\n",
        "        if alt in merged_df.columns:\n",
        "            merged_df['loc_encoded'] = merged_df[alt].astype(str)\n",
        "            break\n",
        "\n",
        "# Sort data by entity & timestamp to ensure correct transition sequence\n",
        "merged_df = merged_df.sort_values(['resolved_entity', 'timestamp']).reset_index(drop=True)\n",
        "\n",
        "# Build transition pairs\n",
        "merged_df['next_loc'] = merged_df.groupby('resolved_entity')['loc_encoded'].shift(-1)\n",
        "\n",
        "# Drop invalid rows\n",
        "transitions_df = merged_df.dropna(subset=['loc_encoded', 'next_loc'])\n",
        "\n",
        "# Compute transition counts\n",
        "transitions = transitions_df.groupby(['loc_encoded', 'next_loc']).size().unstack(fill_value=0)\n",
        "\n",
        "# Normalize to get probabilities\n",
        "markov_matrix = transitions.div(transitions.sum(axis=1), axis=0)\n",
        "\n",
        "print(\"✅ Markov transition matrix built successfully.\")\n",
        "print(f\"Matrix shape: {markov_matrix.shape}\")\n",
        "markov_matrix.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "EuukzP0QTnc3",
        "outputId": "ce41e732-35fc-450b-ea99-53e25de53e30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Building Markov chain transition probabilities...\n",
            "✅ Markov transition matrix built successfully.\n",
            "Matrix shape: (9, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "next_loc          0.0       1.0       2.0       3.0       4.0       5.0  \\\n",
              "loc_encoded                                                               \n",
              "0.0          0.017013  0.018904  0.013233  0.017013  0.013233  0.005671   \n",
              "1.0          0.013060  0.018657  0.022388  0.005597  0.024254  0.013060   \n",
              "2.0          0.017857  0.013889  0.015873  0.019841  0.021825  0.009921   \n",
              "3.0          0.015267  0.013359  0.011450  0.022901  0.019084  0.015267   \n",
              "4.0          0.018797  0.026316  0.018797  0.011278  0.020677  0.016917   \n",
              "\n",
              "next_loc          6.0       7.0       nan  \n",
              "loc_encoded                                \n",
              "0.0          0.022684  0.015123  0.877127  \n",
              "1.0          0.018657  0.016791  0.867537  \n",
              "2.0          0.011905  0.011905  0.876984  \n",
              "3.0          0.003817  0.020992  0.877863  \n",
              "4.0          0.011278  0.020677  0.855263  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf9cad4d-6a58-4aa6-94fd-315a0f515f53\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>next_loc</th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "      <th>3.0</th>\n",
              "      <th>4.0</th>\n",
              "      <th>5.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>nan</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loc_encoded</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.017013</td>\n",
              "      <td>0.018904</td>\n",
              "      <td>0.013233</td>\n",
              "      <td>0.017013</td>\n",
              "      <td>0.013233</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>0.022684</td>\n",
              "      <td>0.015123</td>\n",
              "      <td>0.877127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.018657</td>\n",
              "      <td>0.022388</td>\n",
              "      <td>0.005597</td>\n",
              "      <td>0.024254</td>\n",
              "      <td>0.013060</td>\n",
              "      <td>0.018657</td>\n",
              "      <td>0.016791</td>\n",
              "      <td>0.867537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>0.017857</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.015873</td>\n",
              "      <td>0.019841</td>\n",
              "      <td>0.021825</td>\n",
              "      <td>0.009921</td>\n",
              "      <td>0.011905</td>\n",
              "      <td>0.011905</td>\n",
              "      <td>0.876984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>0.015267</td>\n",
              "      <td>0.013359</td>\n",
              "      <td>0.011450</td>\n",
              "      <td>0.022901</td>\n",
              "      <td>0.019084</td>\n",
              "      <td>0.015267</td>\n",
              "      <td>0.003817</td>\n",
              "      <td>0.020992</td>\n",
              "      <td>0.877863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>0.018797</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.018797</td>\n",
              "      <td>0.011278</td>\n",
              "      <td>0.020677</td>\n",
              "      <td>0.016917</td>\n",
              "      <td>0.011278</td>\n",
              "      <td>0.020677</td>\n",
              "      <td>0.855263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf9cad4d-6a58-4aa6-94fd-315a0f515f53')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf9cad4d-6a58-4aa6-94fd-315a0f515f53 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf9cad4d-6a58-4aa6-94fd-315a0f515f53');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-34b38907-6a35-4210-81fe-f925e40673dc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34b38907-6a35-4210-81fe-f925e40673dc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-34b38907-6a35-4210-81fe-f925e40673dc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "markov_matrix",
              "summary": "{\n  \"name\": \"markov_matrix\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"loc_encoded\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"7.0\",\n          \"1.0\",\n          \"5.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"0.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.003259610453901917,\n        \"min\": 0.01009197751660705,\n        \"max\": 0.02131782945736434,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.016605166051660517,\n          0.013059701492537313,\n          0.02131782945736434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006636766142442189,\n        \"min\": 0.00998978027593255,\n        \"max\": 0.02952029520295203,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.02952029520295203,\n          0.018656716417910446,\n          0.011627906976744186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004163086163527727,\n        \"min\": 0.00947879407256004,\n        \"max\": 0.022388059701492536,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.02029520295202952,\n          0.022388059701492536,\n          0.015503875968992248\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005557201001870314,\n        \"min\": 0.005597014925373134,\n        \"max\": 0.022900763358778626,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.01845018450184502,\n          0.005597014925373134,\n          0.01744186046511628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"4.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005400868055122918,\n        \"min\": 0.00922509225092251,\n        \"max\": 0.024253731343283583,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.00922509225092251,\n          0.024253731343283583,\n          0.01744186046511628\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0066294562648058835,\n        \"min\": 0.005671077504725898,\n        \"max\": 0.029069767441860465,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.014760147601476014,\n          0.013059701492537313,\n          0.029069767441860465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"6.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0070491497710009265,\n        \"min\": 0.003816793893129771,\n        \"max\": 0.022684310018903593,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.005535055350553505,\n          0.018656716417910446,\n          0.02131782945736434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"7.0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005301365861151685,\n        \"min\": 0.010194174757281554,\n        \"max\": 0.026415094339622643,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.01845018450184502,\n          0.016791044776119403,\n          0.011627906976744186\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01946532101462016,\n        \"min\": 0.8546511627906976,\n        \"max\": 0.9205416453755748,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.8671586715867159,\n          0.8675373134328358,\n          0.8546511627906976\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_location(current_loc):\n",
        "    if current_loc not in markov_matrix.index:\n",
        "        return None\n",
        "    probs = markov_matrix.loc[current_loc]\n",
        "    return probs.idxmax()  # most likely next location\n",
        "\n",
        "example_loc = merged_df['loc_encoded'].dropna().sample(1).iloc[0]\n",
        "pred = predict_next_location(example_loc)\n",
        "print(f\"From location '{example_loc}', likely next location: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF4hbm3mTrwW",
        "outputId": "79496ad2-9c9c-4a16-9648-8980e1912459"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From location 'nan', likely next location: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15️⃣ SAVE OUTPUTS\n",
        "# ===========================================\n",
        "\n",
        "output_path = os.path.join(DATA_DIR, \"merged_entity_timeline.csv\")\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "joblib.dump(rf, os.path.join(DATA_DIR, \"rf_model.pkl\"))\n",
        "joblib.dump(markov_matrix, os.path.join(DATA_DIR, \"markov_model.pkl\"))\n",
        "\n",
        "print(f\"\\n✅ All done! Outputs saved to {DATA_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RelkmwDjT6ZH",
        "outputId": "cb0a6dbf-7e51-40bf-8eef-883ede98869c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ All done! Outputs saved to /content/drive/MyDrive/campus_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "63QT2cFSUi3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}